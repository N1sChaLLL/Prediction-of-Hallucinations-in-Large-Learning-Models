{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/N1sChaLLL/Prediction-of-Hallucinations-in-Large-Learning-Models/blob/main/BERT_EVALUATION_METRICS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLuqnG-dEQt1",
        "outputId": "913263ee-20b0-4ae2-c045-25f1fbcc4000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data:\n",
            "      Id                                             Prompt  \\\n",
            "0  11527  [INST] You are an AI assistant that helps peop...   \n",
            "1   7322  [INST] You are an AI assistant. You will be gi...   \n",
            "2  11742  [INST] You are an AI assistant. You will be gi...   \n",
            "3  20928  [INST] You are an AI assistant. User will you ...   \n",
            "4  25830  [INST] You are an AI assistant. User will you ...   \n",
            "\n",
            "                                              Answer  Target  \n",
            "0  Step-by-step reasoning process:\\n1. Randy spen...       0  \n",
            "1  What is the temperature at which hypothermia b...       0  \n",
            "2  Answer: c) No. \\n\\nThe hypothesis is false bec...       0  \n",
            "3                                         Prismatoid       0  \n",
            "4                                             Case B       0  \n",
            "\n",
            "Test Data:\n",
            "      Id                                             Prompt  \\\n",
            "0  20568  [INST] You are an AI assistant. You will be gi...   \n",
            "1  17686  question:Question: This article: According to ...   \n",
            "2  13035  [INST] You are an AI assistant. Provide a deta...   \n",
            "3  22646  [INST] You are an AI assistant. User will you ...   \n",
            "4   5535  [INST] You are an AI assistant. You will be gi...   \n",
            "\n",
            "                                              Answer  \n",
            "0  London Irish lost to Grenoble 21-6 in the Euro...  \n",
            "1                                              10.2%  \n",
            "2                                       Can't answer  \n",
            "3  'Ahora, por lo tanto, no eres tú quien me enví...  \n",
            "4  c). can decrease blood pressure \\n d). can dec...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load training data\n",
        "train_data = pd.read_csv('train.csv')  # replace 'train.csv' with your actual file path\n",
        "prompts_train = train_data['Prompt'].tolist()\n",
        "answers_train = train_data['Answer'].tolist()\n",
        "labels_train = train_data['Target'].tolist()  # Target is present in train.csv\n",
        "\n",
        "# Load test data (this does not have 'Target')\n",
        "test_data = pd.read_csv('test.csv')  # replace 'test.csv' with your actual file path\n",
        "prompts_test = test_data['Prompt'].tolist()\n",
        "answers_test = test_data['Answer'].tolist()\n",
        "\n",
        "# Check the first few rows of both datasets\n",
        "print(\"Training Data:\")\n",
        "print(train_data.head())\n",
        "print(\"\\nTest Data:\")\n",
        "print(test_data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z4LoTs2EQt5",
        "outputId": "8c6b4795-1c14-4774-9aac-5fac554386cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\envs\\saturn_2\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Load BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Set the model to evaluation mode (disable gradient calculation)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vD1vYFUEQt6",
        "outputId": "cb37e1ed-316f-48d2-beaf-abda86ec03e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\envs\\saturn_2\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating BERT embeddings for prompts...\n",
            "Generating BERT embeddings for answers...\n",
            "Filtered prompt embeddings shape: (16668, 768)\n",
            "Filtered answer embeddings shape: (16668, 768)\n",
            "Combined embeddings shape: (16668, 1536)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "\n",
        "# Load data (train.csv)\n",
        "data = pd.read_csv('train.csv')\n",
        "\n",
        "# Extract prompts and answers\n",
        "prompts_train = data['Prompt'].tolist()\n",
        "answers_train = data['Answer'].tolist()\n",
        "\n",
        "# Check for rows where either the prompt or answer is missing or empty\n",
        "filtered_prompts, filtered_answers = [], []\n",
        "for prompt, answer in zip(prompts_train, answers_train):\n",
        "    if isinstance(prompt, str) and isinstance(answer, str) and prompt.strip() and answer.strip():\n",
        "        filtered_prompts.append(prompt)\n",
        "        filtered_answers.append(answer)\n",
        "\n",
        "# Load the BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to get BERT embeddings with batch processing\n",
        "def get_bert_embeddings(text_list, batch_size=32):\n",
        "    embeddings = []\n",
        "    for i in range(0, len(text_list), batch_size):\n",
        "        batch_text = text_list[i:i+batch_size]\n",
        "\n",
        "        # Tokenize the batch and convert to PyTorch tensors\n",
        "        inputs = tokenizer(batch_text, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "\n",
        "        # Forward pass through BERT to get embeddings\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            # Take the mean of the last hidden states to get the sentence embedding\n",
        "            batch_embeddings = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "            embeddings.append(batch_embeddings)\n",
        "\n",
        "    # Concatenate all batches to form the final embedding matrix\n",
        "    return np.concatenate(embeddings)\n",
        "\n",
        "# Generate embeddings for filtered training data\n",
        "print(\"Generating BERT embeddings for prompts...\")\n",
        "prompt_embeddings_train = get_bert_embeddings(filtered_prompts)\n",
        "\n",
        "print(\"Generating BERT embeddings for answers...\")\n",
        "answer_embeddings_train = get_bert_embeddings(filtered_answers)\n",
        "\n",
        "# Check the shape of the embeddings\n",
        "print(\"Filtered prompt embeddings shape:\", prompt_embeddings_train.shape)\n",
        "print(\"Filtered answer embeddings shape:\", answer_embeddings_train.shape)\n",
        "\n",
        "# Concatenate prompt and answer embeddings for training data\n",
        "combined_embeddings_train = np.concatenate([prompt_embeddings_train, answer_embeddings_train], axis=1)\n",
        "\n",
        "# Check final embeddings shape\n",
        "print(\"Combined embeddings shape:\", combined_embeddings_train.shape)\n",
        "\n",
        "# Save the embeddings for later use if needed\n",
        "np.save('combined_embeddings_train.npy', combined_embeddings_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0N3FEiOJEQt8",
        "outputId": "a75deb03-bbee-49bc-827d-36959accccd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered Labels shape: (16668,)\n",
            "Training data shape: (13334, 1536)\n",
            "Validation data shape: (3334, 1536)\n",
            "Training labels shape: (13334,)\n",
            "Validation labels shape: (3334,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Get labels (Targets) from your dataset\n",
        "labels_train = data['Target'].tolist()\n",
        "\n",
        "# Filter labels to match filtered prompts and answers\n",
        "filtered_labels = []\n",
        "for i, (prompt, answer) in enumerate(zip(prompts_train, answers_train)):\n",
        "    if isinstance(prompt, str) and isinstance(answer, str) and prompt.strip() and answer.strip():\n",
        "        filtered_labels.append(labels_train[i])\n",
        "\n",
        "# Convert the filtered labels to a NumPy array\n",
        "labels_train_np = np.array(filtered_labels)\n",
        "print(\"Filtered Labels shape:\", labels_train_np.shape)\n",
        "\n",
        "# Split the combined embeddings and labels into training and validation sets (80% train, 20% validation)\n",
        "X_train, X_val, y_train, y_val = train_test_split(combined_embeddings_train, labels_train_np, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print shapes to confirm\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "print(\"Validation data shape:\", X_val.shape)\n",
        "print(\"Training labels shape:\", y_train.shape)\n",
        "print(\"Validation labels shape:\", y_val.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9q_kiT98EQt9",
        "outputId": "742956aa-9955-4fc5-a2e3-39dd002b0e1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training the Logistic Regression classifier...\n",
            "Validation Accuracy: 94.48%\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "No Hallucination       0.96      0.98      0.97      3176\n",
            "   Hallucination       0.33      0.16      0.21       158\n",
            "\n",
            "        accuracy                           0.94      3334\n",
            "       macro avg       0.64      0.57      0.59      3334\n",
            "    weighted avg       0.93      0.94      0.94      3334\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "clf = LogisticRegression(max_iter=1000)  # Increase max_iter to ensure convergence\n",
        "\n",
        "# Train the classifier on the training set\n",
        "print(\"Training the Logistic Regression classifier...\")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred = clf.predict(X_val)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Get a detailed classification report (precision, recall, F1-score)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred, target_names=['No Hallucination', 'Hallucination']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKlY7ncDEQt-",
        "outputId": "818504a4-69e6-4dba-a932-1ed62a52d97d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to logistic_regression_model.pkl\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained Logistic Regression model to a file\n",
        "model_filename = 'logistic_regression_model.pkl'\n",
        "joblib.dump(clf, model_filename)\n",
        "\n",
        "print(f\"Model saved to {model_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxEN59g0EQuA",
        "outputId": "70cb185b-e2a1-4f86-995b-9047dd2fefbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating BERT embeddings for filtered test prompts...\n",
            "Generating BERT embeddings for filtered test answers...\n",
            "Test Predictions: [0 1 0 ... 0 0 0]\n",
            "Predictions saved to test_predictions.csv\n"
          ]
        }
      ],
      "source": [
        "# Ensure the test data is properly cleaned by filtering out invalid rows\n",
        "filtered_prompts_test, filtered_answers_test = [], []\n",
        "for prompt, answer in zip(prompts_test, answers_test):\n",
        "    if isinstance(prompt, str) and isinstance(answer, str) and prompt.strip() and answer.strip():\n",
        "        filtered_prompts_test.append(prompt)\n",
        "        filtered_answers_test.append(answer)\n",
        "\n",
        "# Generate BERT embeddings for the filtered test data (prompts and answers)\n",
        "print(\"Generating BERT embeddings for filtered test prompts...\")\n",
        "prompt_embeddings_test = get_bert_embeddings(filtered_prompts_test)\n",
        "\n",
        "print(\"Generating BERT embeddings for filtered test answers...\")\n",
        "answer_embeddings_test = get_bert_embeddings(filtered_answers_test)\n",
        "\n",
        "# Concatenate prompt and answer embeddings for the test set\n",
        "combined_embeddings_test = np.concatenate([prompt_embeddings_test, answer_embeddings_test], axis=1)\n",
        "\n",
        "# Load the trained model\n",
        "clf = joblib.load('logistic_regression_model.pkl')\n",
        "\n",
        "# Make predictions on the test data\n",
        "test_predictions = clf.predict(combined_embeddings_test)\n",
        "\n",
        "# Output the predictions (1: Hallucination, 0: No Hallucination)\n",
        "print(\"Test Predictions:\", test_predictions)\n",
        "\n",
        "# Save predictions to a CSV file if needed\n",
        "output_df = pd.DataFrame({'Id': test_data['Id'][:len(test_predictions)], 'Prediction': test_predictions})\n",
        "output_df.to_csv('test_predictions.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to test_predictions.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0g5_R5FEQuB"
      },
      "outputs": [],
      "source": [
        "# Assuming data['Target'] contains the target labels\n",
        "y_train = data['Target'].tolist()\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Filter the prompts, answers, and target labels simultaneously\n",
        "filtered_prompts, filtered_answers, filtered_labels = [], [], []\n",
        "for prompt, answer, label in zip(prompts_train, answers_train, y_train):\n",
        "    if isinstance(prompt, str) and isinstance(answer, str) and prompt.strip() and answer.strip():\n",
        "        filtered_prompts.append(prompt)\n",
        "        filtered_answers.append(answer)\n",
        "        filtered_labels.append(label)\n",
        "\n",
        "# Convert the labels to numeric encoding\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(filtered_labels)\n",
        "\n",
        "# Now that the filtering is consistent, you can split the data\n",
        "X = np.concatenate([prompt_embeddings_train, answer_embeddings_train], axis=1)  # Make sure to use filtered embeddings\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
        "\n",
        "# Proceed with evaluating classifiers as before\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa-ZFs7wEQuC",
        "outputId": "c3701f1b-b65c-44e6-864f-55aa940b5697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating Logistic Regression...\n",
            "Evaluating Random Forest...\n",
            "Evaluating SVM...\n",
            "Evaluating KNN...\n",
            "Evaluating Decision Tree...\n",
            "Evaluating Naive Bayes...\n",
            "Evaluating Gradient Boosting...\n",
            "Evaluating AdaBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\envs\\saturn_2\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating MLP Classifier...\n",
            "Evaluating LDA...\n",
            "Evaluating QDA...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\envs\\saturn_2\\lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "c:\\ProgramData\\anaconda3\\envs\\saturn_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\ProgramData\\anaconda3\\envs\\saturn_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating Extra Trees...\n",
            "Evaluating Bagging Classifier...\n",
            "Evaluating Ridge Classifier...\n",
            "Evaluating Perceptron...\n",
            "             Classifier  Train Accuracy  Val Accuracy  Train F1    Val F1  \\\n",
            "0   Logistic Regression        0.961902      0.941812  0.953934  0.932226   \n",
            "1         Random Forest        0.999400      0.950510  0.999401  0.932070   \n",
            "2                   SVM        0.949528      0.949010  0.927834  0.926910   \n",
            "3                   KNN        0.954627      0.946911  0.942517  0.933160   \n",
            "4         Decision Tree        0.999475      0.900420  0.999476  0.907193   \n",
            "5           Naive Bayes        0.732563      0.720156  0.805632  0.797023   \n",
            "6     Gradient Boosting        0.958077      0.948710  0.945188  0.931732   \n",
            "7              AdaBoost        0.948928      0.943311  0.934153  0.928997   \n",
            "8        MLP Classifier        0.998500      0.934913  0.998507  0.928916   \n",
            "9                   LDA        0.960027      0.932513  0.957195  0.930067   \n",
            "10                  QDA        0.947053      0.947211  0.921299  0.921531   \n",
            "11          Extra Trees        0.999475      0.950510  0.999476  0.931187   \n",
            "12   Bagging Classifier        0.990325      0.948110  0.989919  0.930519   \n",
            "13     Ridge Classifier        0.952452      0.950510  0.934828  0.930267   \n",
            "14           Perceptron        0.948553      0.915717  0.950474  0.920016   \n",
            "\n",
            "    Train Precision  Val Precision  Train Recall  Val Recall  \n",
            "0          0.958434       0.926670      0.961902    0.941812  \n",
            "1          0.999403       0.940742      0.999400    0.950510  \n",
            "2          0.946245       0.941569      0.949528    0.949010  \n",
            "3          0.946742       0.929803      0.954627    0.946911  \n",
            "4          0.999477       0.914576      0.999475    0.900420  \n",
            "5          0.928484       0.926210      0.732563    0.720156  \n",
            "6          0.958497       0.932554      0.958077    0.948710  \n",
            "7          0.933717       0.922591      0.948928    0.943311  \n",
            "8          0.998525       0.924148      0.998500    0.934913  \n",
            "9          0.955818       0.927842      0.960027    0.932513  \n",
            "10         0.896909       0.897208      0.947053    0.947211  \n",
            "11         0.999477       0.942883      0.999475    0.950510  \n",
            "12         0.990306       0.930563      0.990325    0.948110  \n",
            "13         0.949241       0.946443      0.952452    0.950510  \n",
            "14         0.952811       0.924765      0.948553    0.915717  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.ensemble import ExtraTreesClassifier, BaggingClassifier\n",
        "from sklearn.linear_model import RidgeClassifier, Perceptron\n",
        "\n",
        "# List of classifiers\n",
        "classifiers = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"MLP Classifier\": MLPClassifier(max_iter=1000),\n",
        "    \"LDA\": LinearDiscriminantAnalysis(),\n",
        "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
        "    \"Extra Trees\": ExtraTreesClassifier(),\n",
        "    \"Bagging Classifier\": BaggingClassifier(),\n",
        "    \"Ridge Classifier\": RidgeClassifier(),\n",
        "    \"Perceptron\": Perceptron(),\n",
        "}\n",
        "\n",
        "# Initialize a DataFrame to store the results\n",
        "results_df = pd.DataFrame(columns=[\n",
        "    \"Classifier\", \"Train Accuracy\", \"Val Accuracy\", \"Train F1\", \"Val F1\",\n",
        "    \"Train Precision\", \"Val Precision\", \"Train Recall\", \"Val Recall\"\n",
        "])\n",
        "\n",
        "# Function to evaluate and store metrics\n",
        "def evaluate_classifier(clf_name, clf, X_train, y_train, X_val, y_val):\n",
        "    # Train the classifier\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_train_pred = clf.predict(X_train)\n",
        "    y_val_pred = clf.predict(X_val)\n",
        "\n",
        "    # Calculate metrics\n",
        "    train_acc = accuracy_score(y_train, y_train_pred)\n",
        "    val_acc = accuracy_score(y_val, y_val_pred)\n",
        "    train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
        "    val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
        "    train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
        "    val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
        "    train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
        "    val_recall = recall_score(y_val, y_val_pred, average='weighted')\n",
        "\n",
        "    # Append the results to the DataFrame\n",
        "    results_df.loc[len(results_df)] = [\n",
        "        clf_name, train_acc, val_acc, train_f1, val_f1,\n",
        "        train_precision, val_precision, train_recall, val_recall\n",
        "    ]\n",
        "\n",
        "# Loop through classifiers and evaluate each one\n",
        "for clf_name, clf in classifiers.items():\n",
        "    print(f\"Evaluating {clf_name}...\")\n",
        "    evaluate_classifier(clf_name, clf, X_train, y_train, X_val, y_val)\n",
        "\n",
        "# Display the results\n",
        "print(results_df)\n",
        "\n",
        "# Optionally, save the results to a CSV file\n",
        "results_df.to_csv('classifier_comparison_results.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "saturn_2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}